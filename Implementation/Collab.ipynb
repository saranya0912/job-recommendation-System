{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import sys\n",
    "#print(sys.path)\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "from os import listdir\n",
    "import glob\n",
    "from scipy import spatial\n",
    "#import spacy\n",
    "\n",
    "df=pd.read_csv(\"Documents/data/job_sample.csv\",encoding='cp850')\n",
    "df1=pd.read_csv(\"Documents/data/survey_results_public.csv\",encoding='cp850')\n",
    "#print(df.head())\n",
    "l=list(df[\"company\"])\n",
    "#print(type(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8156"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies=set(l)\n",
    "print(len(companies))\n",
    "#print(companies)\n",
    "companies=list(companies)\n",
    "len(companies)\n",
    "#print(companies[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537.2178292274475\n",
      "   Respondent                                    company\n",
      "0           1                     Magna Infotech Pvt Ltd\n",
      "1           3            InstaCar Technologies Pvt. Ltd.\n",
      "2           4                        Flatworld Solutions\n",
      "3           5  Lordi Systems Staffing Solutions Pvt. Ltd\n",
      "4           7                              RIGHTRESOURCE\n"
     ]
    }
   ],
   "source": [
    "cbf = pd.DataFrame(df1['Respondent'])\n",
    "import time\n",
    "start=time.time()\n",
    "for i in range(98855):\n",
    "    r=random.randint(1,4291)\n",
    "    cbf.loc[i,\"company\"]=l[r]\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(cbf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbf.to_csv(\"Documents/data/colabdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all the dataset having skills from user profile.\n",
    "dflang=pd.read_csv(\"Documents/data/LanguageWorkedWith.csv\")\n",
    "dfdata=pd.read_csv(\"Documents/data/DatabaseWorkedWith.csv\")\n",
    "dfplat=pd.read_csv(\"Documents/data/PlatformWorkedWith.csv\")\n",
    "dfframe=pd.read_csv(\"Documents/data/FrameworkWorkedWith.csv\")\n",
    "dfdev=pd.read_csv(\"Documents/data/DevType.csv\")\n",
    "dfmerge=pd.merge(dflang,dfdata,on=\"Respondent\")\n",
    "dfmerge=pd.merge(dfmerge,dfplat,on=\"Respondent\")\n",
    "dfmerge=pd.merge(dfmerge,dfframe,on=\"Respondent\")\n",
    "dfmerge=pd.merge(dfmerge,dfdev,on=\"Respondent\")\n",
    "#dfmerge.to_csv(\"Documents/data/userskills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101592\n",
      "<class 'int'>\n",
      "[1. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1.]\n",
      "9.467660427093506\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "dfuser=pd.read_csv(\"Documents/data/userskills.csv\")\n",
    "#remove duplicate columns during merge\n",
    "dfuser = dfuser.loc[:,~dfuser.columns.duplicated()]\n",
    "dfuser=dfuser.fillna(0)\n",
    "dfuser.shape\n",
    "dfuser.head()\n",
    "#remove rows with less than 5 skills\n",
    "dfuser=dfuser.dropna(thresh=5)\n",
    "dfuser.shape\n",
    "m=(np.asscalar(np.int32(max(dfuser[\"Respondent\"]))))\n",
    "print(m)\n",
    "print(type(m))\n",
    "#Build  a dictionary of respondent id's as keys  and thier skills as values\n",
    "temp=[0]*m\n",
    "vector=np.array(temp)\n",
    "count=1\n",
    "start=time.time()\n",
    "d=dict()\n",
    "for row in dfuser.iterrows():\n",
    "        index,data=row\n",
    "        l=list()\n",
    "        #l=[data.values[0],list(data.values[1:])]\n",
    "        s=np.asscalar(np.int32(data.values[0]))\n",
    "        d[s]=np.array(list(data.values[1:]))\n",
    "        #print(type(data))\n",
    "end=time.time()\n",
    "print(d[1])\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47673487663269043\n"
     ]
    }
   ],
   "source": [
    "#Build the user user similarity matrix based on thier skill vectors\n",
    "#initialise a user user matrix uptill respondent number 5000\n",
    "sim=list()\n",
    "s=time.time()\n",
    "for i in range(5000):\n",
    "        l=list()\n",
    "        l=[0]*5000\n",
    "        sim.append(l)\n",
    "e=time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time for building similarity matrix \n",
      "357.024533033371\n"
     ]
    }
   ],
   "source": [
    "count1=1\n",
    "count2=1\n",
    "t=time.time()\n",
    "for key, value in d.items():\n",
    "        if(key<5000):\n",
    "            #print(key)\n",
    "            b=(np.linalg.norm(value))\n",
    "            for key2,value2 in d.items():\n",
    "                if(key2<5000):\n",
    "                    #print(key2)\n",
    "                    a=np.dot(d[key],d[key2])\n",
    "                    ans=a/(np.linalg.norm(value2)*b)\n",
    "                    sim[key][key2]=ans\n",
    "                    #count2+=1\n",
    "            #count1+=1\n",
    "e=time.time()\n",
    "print(\"total time for building similarity matrix \")\n",
    "print(e-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4622501635210243, 1.0000000000000002, 0.7317274774221446, 0.7190924955066748, 0.6955416066888231, 0.7432913296668157, 0.7147924077695138, 0.6821910402406466, 0.7437443194099495, 0.7088711145405624]\n",
      "0.7437443194099495\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#print(e-s)\n",
    "print(sim[1][:10])\n",
    "# the similarity of user 1 with others \n",
    "print((max(sim[1][2:])))\n",
    "print(sim[1].index(max(sim[1][2:])))\n",
    "#user 1 is most similar to user 4653 with similarity 0.71 in skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respondent 3 is working in \n",
      "['My Connecting']\n",
      "Respondent  7 is working in\n",
      "['Ansal Properties & Infrastructure Ltd.']\n"
     ]
    }
   ],
   "source": [
    "#Lets check with the random jobs given to the users .\n",
    "dfjob=pd.read_csv(\"Documents/data/colabdata.csv\")\n",
    "#Recommend user 3 a job based on another user who has almost the same skill as him.\n",
    "print(\"Respondent 3 is working in \")\n",
    "print(dfjob.loc[dfjob.Respondent==3][\"company\"].values)\n",
    "\n",
    "m1=max(sim[3][:3])\n",
    "m2=max(sim[3][4:])\n",
    "ma=max(m1,m2)\n",
    "suser=sim[3].index(ma)\n",
    "#print(suser) #user ___ is very similar to user 3 and hence we can recommend user 3265 job to user 3.\n",
    "print(\"Respondent \",suser,\"is working in\")\n",
    "print(dfjob.loc[dfjob.Respondent==suser][\"company\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002955198287963867\n",
      "Building the similarity matrix....\n",
      "\n",
      "4.413245677947998\n"
     ]
    }
   ],
   "source": [
    "#For buiding  collaborative filtering based on The Content based recommendations\n",
    "dfcont=pd.read_csv(\"Documents/data/recommendations.csv\")\n",
    "sim=list()\n",
    "s=time.time()\n",
    "for i in range(200):\n",
    "        l=list()\n",
    "        l=[0]*200\n",
    "        sim.append(l)\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "t=time.time()\n",
    "print(\"Building the similarity matrix....\\n\")\n",
    "for key, value in d.items():\n",
    "        if(key<200):\n",
    "            #print(key)\n",
    "            b=(np.linalg.norm(value))\n",
    "            for key2,value2 in d.items():\n",
    "                if(key2<200):\n",
    "                    #print(key2)\n",
    "                    a=np.dot(d[key],d[key2])\n",
    "                    ans=a/(np.linalg.norm(value2)*b)\n",
    "                    sim[key][key2]=ans\n",
    "                    #count2+=1\n",
    "            #count1+=1\n",
    "e=time.time()\n",
    "print(e-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respondent 3 was recommended job titles from content based filtering \n",
      "['Python Developer' 'Full-Stack Python Developer'\n",
      " 'Full Stack Javascript Engineer' 'Full Stack Developer'\n",
      " 'System Administrator' 'System Administrator' 'Application Administrator'\n",
      " 'Application Administrator' 'System Administrator' 'Full Stack Engineer']\n",
      "\n",
      "\n",
      "Similarity Accuracy:  0.9343298097444914\n",
      "51\n",
      "Respondent  51 was most similiar to respondent 3\n",
      "\n",
      "Based on respondent  51  the jobs recommended to 3 are \n",
      "The recommended job titles are \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Software Engineer MEAN, Angular.js, Node.js, MySQLRiccione Resources, Inc.',\n",
       "       'Sr. Software Engineer, The Huffington PostEdgeCast Networks, Inc.',\n",
       "       'Senior Front End Web Developer - Full Time at VisaOmega Solutions Inc',\n",
       "       'Hybrid Mobile Developer - HTML5, CSS3, AngularJSCyberCoders',\n",
       "       'Full Time: Senior .Net Developer in Salt Lake City, UTEndure Technology Solutions, Inc.',\n",
       "       'Senior Full Stack EngineerLithium Technologies, Inc.',\n",
       "       'Front End Software EngineerThorndale Partners LLC',\n",
       "       'Front End Software EngineerThorndale Partners LLC',\n",
       "       'Front End Web DeveloperIncendia Partners',\n",
       "       'Full Stack Javascript EngineerDST Systems, Inc'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Respondent 3 was recommended job titles from content based filtering \")\n",
    "print(dfcont.loc[dfcont.Respondent==3][\"jobtitle\"].values)\n",
    "print(\"\\n\")\n",
    "m1=max(sim[3][:3])\n",
    "m2=max(sim[3][50:])\n",
    "ma=max(m1,m2)\n",
    "print(\"Similarity Accuracy: \",ma)\n",
    "suser=sim[3].index(ma)\n",
    "print(suser) #user 3265 is very similar to user 3 and hence we can recommend user 3265 job to user 3.\n",
    "print(\"Respondent \",suser,\"was most similiar to respondent 3\\n\")\n",
    "print(\"Based on respondent \",suser,\" the jobs recommended to 3 are \")\n",
    "#print(dfcont.loc[dfcont.Respondent==suser][\"company\"].values)\n",
    "print(\"The recommended job titles are \")\n",
    "jobs=dfcont.loc[dfcont.Respondent==suser][\"jobtitle\"].values+dfcont.loc[dfcont.Respondent==suser][\"company\"].values\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
